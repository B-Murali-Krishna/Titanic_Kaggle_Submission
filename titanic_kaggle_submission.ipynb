{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic_kaggle_submission.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxfCon-D-Tza"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_a2OKSU_GxI",
        "outputId": "705c523a-aa1d-4b2b-ccb2-5a37a4616682"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/B-Murali-Krishna/Projects/main/helper_functions.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-08 17:28:16--  https://raw.githubusercontent.com/B-Murali-Krishna/Projects/main/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14217 (14K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  13.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-08 17:28:17 (61.0 MB/s) - ‘helper_functions.py’ saved [14217/14217]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGArPzVv_V4O"
      },
      "source": [
        "from helper_functions import unzip_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOuB7Hpy_f-8"
      },
      "source": [
        "df = unzip_data('titanic.zip')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9fxuLtck_rql",
        "outputId": "33266fef-1923-4367-fe18-e5c31ef2254b"
      },
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "train_df"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0              1         0       3  ...   7.2500   NaN         S\n",
              "1              2         1       1  ...  71.2833   C85         C\n",
              "2              3         1       3  ...   7.9250   NaN         S\n",
              "3              4         1       1  ...  53.1000  C123         S\n",
              "4              5         0       3  ...   8.0500   NaN         S\n",
              "..           ...       ...     ...  ...      ...   ...       ...\n",
              "886          887         0       2  ...  13.0000   NaN         S\n",
              "887          888         1       1  ...  30.0000   B42         S\n",
              "888          889         0       3  ...  23.4500   NaN         S\n",
              "889          890         1       1  ...  30.0000  C148         C\n",
              "890          891         0       3  ...   7.7500   NaN         Q\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS1F2uR9AJ9j",
        "outputId": "54853fb9-bcbd-443d-8d6f-75aa7aeb3935"
      },
      "source": [
        "train_df.isna().sum()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "_iUiO62WAWPZ",
        "outputId": "522d5517-f474-4f64-9ba5-b368fe94c8dd"
      },
      "source": [
        "# We can drop the cabin column because it is having 687 Nan values out of 891 rows\n",
        "train_df = train_df.drop(columns=['Cabin','Age','Name','Ticket'])\n",
        "train_df"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass     Sex  SibSp  Parch     Fare Embarked\n",
              "0              1         0       3    male      1      0   7.2500        S\n",
              "1              2         1       1  female      1      0  71.2833        C\n",
              "2              3         1       3  female      0      0   7.9250        S\n",
              "3              4         1       1  female      1      0  53.1000        S\n",
              "4              5         0       3    male      0      0   8.0500        S\n",
              "..           ...       ...     ...     ...    ...    ...      ...      ...\n",
              "886          887         0       2    male      0      0  13.0000        S\n",
              "887          888         1       1  female      0      0  30.0000        S\n",
              "888          889         0       3  female      1      2  23.4500        S\n",
              "889          890         1       1    male      0      0  30.0000        C\n",
              "890          891         0       3    male      0      0   7.7500        Q\n",
              "\n",
              "[891 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XenDRGDJBhBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59519664-84bb-4c20-fc29-ab8e05d61b5d"
      },
      "source": [
        "train_df.isna().sum()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId    0\n",
              "Survived       0\n",
              "Pclass         0\n",
              "Sex            0\n",
              "SibSp          0\n",
              "Parch          0\n",
              "Fare           0\n",
              "Embarked       2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugtt0JkY0gzS",
        "outputId": "ef41b0a4-aad0-43f8-e7ff-841eed906e94"
      },
      "source": [
        "train_df['Embarked'].value_counts()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "S    644\n",
              "C    168\n",
              "Q     77\n",
              "Name: Embarked, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nITa--bI0g6i"
      },
      "source": [
        "train_df['Embarked'].fillna(value='S',inplace=True)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgryLYuK0g9r",
        "outputId": "88c713d1-74d4-4338-fe3e-13dfb3b0d4fd"
      },
      "source": [
        "train_df['Embarked'].value_counts()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "S    646\n",
              "C    168\n",
              "Q     77\n",
              "Name: Embarked, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsoA5iKe0hAD",
        "outputId": "2731454d-047b-479a-93d1-d76473a7e48d"
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Sex          891 non-null    object \n",
            " 4   SibSp        891 non-null    int64  \n",
            " 5   Parch        891 non-null    int64  \n",
            " 6   Fare         891 non-null    float64\n",
            " 7   Embarked     891 non-null    object \n",
            "dtypes: float64(1), int64(5), object(2)\n",
            "memory usage: 55.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLOLKtne2Ow_"
      },
      "source": [
        "train_df.drop('Fare',axis=1,inplace=True)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ytMvWH82O1M"
      },
      "source": [
        "train_df.drop('PassengerId',axis=1,inplace=True)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "LzhN-Zaq2O5V",
        "outputId": "1d1d4d11-6c01-472d-b065-d21386d95dc1"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived  Pclass     Sex  SibSp  Parch Embarked\n",
              "0           0       3    male      1      0        S\n",
              "1           1       1  female      1      0        C\n",
              "2           1       3  female      0      0        S\n",
              "3           1       1  female      1      0        S\n",
              "4           0       3    male      0      0        S\n",
              "..        ...     ...     ...    ...    ...      ...\n",
              "886         0       2    male      0      0        S\n",
              "887         1       1  female      0      0        S\n",
              "888         0       3  female      1      2        S\n",
              "889         1       1    male      0      0        C\n",
              "890         0       3    male      0      0        Q\n",
              "\n",
              "[891 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZDpz4hH2O7_"
      },
      "source": [
        "train_df_one_hot = pd.get_dummies(train_df) "
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "_U3yHlXw6Y0o",
        "outputId": "04e90615-08d3-4d87-e9dc-27e7275f7475"
      },
      "source": [
        "train_df_one_hot"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived  Pclass  SibSp  ...  Embarked_C  Embarked_Q  Embarked_S\n",
              "0           0       3      1  ...           0           0           1\n",
              "1           1       1      1  ...           1           0           0\n",
              "2           1       3      0  ...           0           0           1\n",
              "3           1       1      1  ...           0           0           1\n",
              "4           0       3      0  ...           0           0           1\n",
              "..        ...     ...    ...  ...         ...         ...         ...\n",
              "886         0       2      0  ...           0           0           1\n",
              "887         1       1      0  ...           0           0           1\n",
              "888         0       3      1  ...           0           0           1\n",
              "889         1       1      0  ...           1           0           0\n",
              "890         0       3      0  ...           0           1           0\n",
              "\n",
              "[891 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlmpafoK2PAV",
        "outputId": "e53c44fd-883f-45fa-d796-16dc6326ba2f"
      },
      "source": [
        "x = train_df_one_hot.drop('Survived',axis=1)\n",
        "y = train_df_one_hot['Survived']\n",
        "x,y"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(     Pclass  SibSp  Parch  ...  Embarked_C  Embarked_Q  Embarked_S\n",
              " 0         3      1      0  ...           0           0           1\n",
              " 1         1      1      0  ...           1           0           0\n",
              " 2         3      0      0  ...           0           0           1\n",
              " 3         1      1      0  ...           0           0           1\n",
              " 4         3      0      0  ...           0           0           1\n",
              " ..      ...    ...    ...  ...         ...         ...         ...\n",
              " 886       2      0      0  ...           0           0           1\n",
              " 887       1      0      0  ...           0           0           1\n",
              " 888       3      1      2  ...           0           0           1\n",
              " 889       1      0      0  ...           1           0           0\n",
              " 890       3      0      0  ...           0           1           0\n",
              " \n",
              " [891 rows x 8 columns], 0      0\n",
              " 1      1\n",
              " 2      1\n",
              " 3      1\n",
              " 4      0\n",
              "       ..\n",
              " 886    0\n",
              " 887    1\n",
              " 888    0\n",
              " 889    1\n",
              " 890    0\n",
              " Name: Survived, Length: 891, dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a82oOPZx2PCz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, \n",
        "                                                    y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=42)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPHxeZhg2PJm",
        "outputId": "a28e5cac-d6f6-4430-a5fd-080f1b696610"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model using the Sequential API\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(20),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_1.fit(x_train, y_train,\n",
        "            validation_data=(x_test,y_test),\n",
        "            epochs=100)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 8ms/step - loss: 4.1923 - accuracy: 0.5351 - val_loss: 3.4724 - val_accuracy: 0.3799\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1936 - accuracy: 0.4171 - val_loss: 1.8161 - val_accuracy: 0.6034\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1093 - accuracy: 0.6433 - val_loss: 0.8674 - val_accuracy: 0.6480\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7266 - accuracy: 0.6840 - val_loss: 0.7062 - val_accuracy: 0.7709\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.7879 - val_loss: 0.5841 - val_accuracy: 0.7821\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.8076 - val_loss: 0.5023 - val_accuracy: 0.7821\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7935 - val_loss: 0.4709 - val_accuracy: 0.7821\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7893 - val_loss: 0.4603 - val_accuracy: 0.7821\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7893 - val_loss: 0.4518 - val_accuracy: 0.7821\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7935 - val_loss: 0.4529 - val_accuracy: 0.7877\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7935 - val_loss: 0.4510 - val_accuracy: 0.7877\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7949 - val_loss: 0.4520 - val_accuracy: 0.7821\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7949 - val_loss: 0.4425 - val_accuracy: 0.7877\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7907 - val_loss: 0.4545 - val_accuracy: 0.7654\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7949 - val_loss: 0.4469 - val_accuracy: 0.7877\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7893 - val_loss: 0.4464 - val_accuracy: 0.7821\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7823 - val_loss: 0.4857 - val_accuracy: 0.7654\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7795 - val_loss: 0.4607 - val_accuracy: 0.7598\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7795 - val_loss: 0.4607 - val_accuracy: 0.7598\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7879 - val_loss: 0.4417 - val_accuracy: 0.7877\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7893 - val_loss: 0.4719 - val_accuracy: 0.7654\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7907 - val_loss: 0.4935 - val_accuracy: 0.7709\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.8062 - val_loss: 0.4626 - val_accuracy: 0.7821\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7893 - val_loss: 0.4532 - val_accuracy: 0.7933\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7907 - val_loss: 0.4501 - val_accuracy: 0.7821\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7907 - val_loss: 0.4692 - val_accuracy: 0.7933\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7949 - val_loss: 0.4697 - val_accuracy: 0.7877\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7949 - val_loss: 0.4524 - val_accuracy: 0.7877\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7935 - val_loss: 0.4645 - val_accuracy: 0.7821\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7865 - val_loss: 0.4589 - val_accuracy: 0.7821\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7907 - val_loss: 0.4608 - val_accuracy: 0.7933\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.7781 - val_loss: 0.9628 - val_accuracy: 0.7318\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8007 - accuracy: 0.7402 - val_loss: 0.5196 - val_accuracy: 0.7765\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7992 - val_loss: 0.5092 - val_accuracy: 0.7709\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7921 - val_loss: 0.4606 - val_accuracy: 0.7877\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7992 - val_loss: 0.4585 - val_accuracy: 0.7765\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7949 - val_loss: 0.4653 - val_accuracy: 0.7765\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.7374 - val_loss: 0.5967 - val_accuracy: 0.6760\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7289 - val_loss: 0.5653 - val_accuracy: 0.7151\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7654 - val_loss: 0.5305 - val_accuracy: 0.7877\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7921 - val_loss: 0.4979 - val_accuracy: 0.7821\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7978 - val_loss: 0.4868 - val_accuracy: 0.7821\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7921 - val_loss: 0.4749 - val_accuracy: 0.7821\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7921 - val_loss: 0.4655 - val_accuracy: 0.7821\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7921 - val_loss: 0.4632 - val_accuracy: 0.7821\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7921 - val_loss: 0.4531 - val_accuracy: 0.7821\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7921 - val_loss: 0.4615 - val_accuracy: 0.7821\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7893 - val_loss: 0.4493 - val_accuracy: 0.7821\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7935 - val_loss: 0.4503 - val_accuracy: 0.7877\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7935 - val_loss: 0.4478 - val_accuracy: 0.7821\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7935 - val_loss: 0.4544 - val_accuracy: 0.7821\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7879 - val_loss: 0.4458 - val_accuracy: 0.7821\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7879 - val_loss: 0.4466 - val_accuracy: 0.7821\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7921 - val_loss: 0.4511 - val_accuracy: 0.7877\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7935 - val_loss: 0.4486 - val_accuracy: 0.7821\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7963 - val_loss: 0.4485 - val_accuracy: 0.7821\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7935 - val_loss: 0.4471 - val_accuracy: 0.7821\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7935 - val_loss: 0.4522 - val_accuracy: 0.7821\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7865 - val_loss: 0.4470 - val_accuracy: 0.7821\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7893 - val_loss: 0.4485 - val_accuracy: 0.7877\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7963 - val_loss: 0.4526 - val_accuracy: 0.7821\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7921 - val_loss: 0.4530 - val_accuracy: 0.7821\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7935 - val_loss: 0.4481 - val_accuracy: 0.7877\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7935 - val_loss: 0.4533 - val_accuracy: 0.7821\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7935 - val_loss: 0.4572 - val_accuracy: 0.7821\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7921 - val_loss: 0.4424 - val_accuracy: 0.7821\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7935 - val_loss: 0.4533 - val_accuracy: 0.7765\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7893 - val_loss: 0.4497 - val_accuracy: 0.7654\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7907 - val_loss: 0.4453 - val_accuracy: 0.7821\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7921 - val_loss: 0.4448 - val_accuracy: 0.7654\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7879 - val_loss: 0.4628 - val_accuracy: 0.7654\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7767 - val_loss: 0.4647 - val_accuracy: 0.7765\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7992 - val_loss: 0.4553 - val_accuracy: 0.7709\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7879 - val_loss: 0.4435 - val_accuracy: 0.7877\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7921 - val_loss: 0.4475 - val_accuracy: 0.7654\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7837 - val_loss: 0.4407 - val_accuracy: 0.7654\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7893 - val_loss: 0.4424 - val_accuracy: 0.7709\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7935 - val_loss: 0.4572 - val_accuracy: 0.7598\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7935 - val_loss: 0.4488 - val_accuracy: 0.7598\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7907 - val_loss: 0.4451 - val_accuracy: 0.7933\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7935 - val_loss: 0.4502 - val_accuracy: 0.7709\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7879 - val_loss: 0.4411 - val_accuracy: 0.7877\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7935 - val_loss: 0.4467 - val_accuracy: 0.7821\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7921 - val_loss: 0.4415 - val_accuracy: 0.7877\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7921 - val_loss: 0.4433 - val_accuracy: 0.7821\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7879 - val_loss: 0.4430 - val_accuracy: 0.7877\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7865 - val_loss: 0.4438 - val_accuracy: 0.7821\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7921 - val_loss: 0.4536 - val_accuracy: 0.7709\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8048 - val_loss: 0.4542 - val_accuracy: 0.7709\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7879 - val_loss: 0.4517 - val_accuracy: 0.7598\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7893 - val_loss: 0.4468 - val_accuracy: 0.7933\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7879 - val_loss: 0.6275 - val_accuracy: 0.7821\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.7654 - val_loss: 0.4607 - val_accuracy: 0.7654\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7978 - val_loss: 0.4697 - val_accuracy: 0.7709\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7935 - val_loss: 0.4505 - val_accuracy: 0.7709\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7949 - val_loss: 0.4490 - val_accuracy: 0.7654\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0476 - accuracy: 0.7191 - val_loss: 1.2396 - val_accuracy: 0.7374\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2834 - accuracy: 0.7331 - val_loss: 0.8345 - val_accuracy: 0.7486\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7676 - accuracy: 0.7669 - val_loss: 0.4812 - val_accuracy: 0.7654\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7992 - val_loss: 0.4708 - val_accuracy: 0.7877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f32e4061a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15IxFcjP2PON",
        "outputId": "23991f85-dcc9-4080-f69b-7f88f8693dbb"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model using the Sequential API\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(8),\n",
        "  tf.keras.layers.Dense(4),\n",
        "  tf.keras.layers.Dense(2),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_2.fit(x_train, y_train,\n",
        "            validation_data=(x_test,y_test),\n",
        "            epochs=100)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 9ms/step - loss: 2.6700 - accuracy: 0.6236 - val_loss: 1.6368 - val_accuracy: 0.5866\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3531 - accuracy: 0.6236 - val_loss: 0.9584 - val_accuracy: 0.5866\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.8785 - accuracy: 0.6250 - val_loss: 0.8575 - val_accuracy: 0.6201\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7890 - accuracy: 0.6334 - val_loss: 0.7707 - val_accuracy: 0.6201\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7542 - accuracy: 0.6404 - val_loss: 0.7126 - val_accuracy: 0.6201\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.7276 - accuracy: 0.6419 - val_loss: 0.6791 - val_accuracy: 0.6201\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.6433 - val_loss: 0.6656 - val_accuracy: 0.6201\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6566 - accuracy: 0.6531 - val_loss: 0.6526 - val_accuracy: 0.6369\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6713 - val_loss: 0.6452 - val_accuracy: 0.6480\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6854 - val_loss: 0.6384 - val_accuracy: 0.6480\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6854 - val_loss: 0.6320 - val_accuracy: 0.6480\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6840 - val_loss: 0.6254 - val_accuracy: 0.6592\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6868 - val_loss: 0.6189 - val_accuracy: 0.6592\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6910 - val_loss: 0.6123 - val_accuracy: 0.6592\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6938 - val_loss: 0.6061 - val_accuracy: 0.6983\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.7079 - val_loss: 0.6003 - val_accuracy: 0.7039\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7191 - val_loss: 0.5944 - val_accuracy: 0.7039\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.7303 - val_loss: 0.5881 - val_accuracy: 0.7151\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.7331 - val_loss: 0.5821 - val_accuracy: 0.7151\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7430 - val_loss: 0.5769 - val_accuracy: 0.7318\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7374 - val_loss: 0.5717 - val_accuracy: 0.6983\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7416 - val_loss: 0.5664 - val_accuracy: 0.7207\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7612 - val_loss: 0.5644 - val_accuracy: 0.7486\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7570 - val_loss: 0.5590 - val_accuracy: 0.7598\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7654 - val_loss: 0.5533 - val_accuracy: 0.7598\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7654 - val_loss: 0.5479 - val_accuracy: 0.7598\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7725 - val_loss: 0.5434 - val_accuracy: 0.7709\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7851 - val_loss: 0.5392 - val_accuracy: 0.7821\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7865 - val_loss: 0.5347 - val_accuracy: 0.7821\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7907 - val_loss: 0.5312 - val_accuracy: 0.7821\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7949 - val_loss: 0.5273 - val_accuracy: 0.7933\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7935 - val_loss: 0.5227 - val_accuracy: 0.7877\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7963 - val_loss: 0.5193 - val_accuracy: 0.7933\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7992 - val_loss: 0.5153 - val_accuracy: 0.7877\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.8006 - val_loss: 0.5131 - val_accuracy: 0.7821\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.8006 - val_loss: 0.5096 - val_accuracy: 0.7821\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.8006 - val_loss: 0.5057 - val_accuracy: 0.7821\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7992 - val_loss: 0.5036 - val_accuracy: 0.7821\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8006 - val_loss: 0.5013 - val_accuracy: 0.7877\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8006 - val_loss: 0.4982 - val_accuracy: 0.7877\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7992 - val_loss: 0.4953 - val_accuracy: 0.7877\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.8006 - val_loss: 0.4921 - val_accuracy: 0.7877\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.8006 - val_loss: 0.4904 - val_accuracy: 0.7877\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7978 - val_loss: 0.4883 - val_accuracy: 0.7877\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7978 - val_loss: 0.4863 - val_accuracy: 0.7877\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7963 - val_loss: 0.4851 - val_accuracy: 0.7765\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7978 - val_loss: 0.4818 - val_accuracy: 0.7877\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7921 - val_loss: 0.4810 - val_accuracy: 0.7765\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7921 - val_loss: 0.4788 - val_accuracy: 0.7765\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7935 - val_loss: 0.4774 - val_accuracy: 0.7765\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7921 - val_loss: 0.4753 - val_accuracy: 0.7765\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7921 - val_loss: 0.4743 - val_accuracy: 0.7765\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7907 - val_loss: 0.4730 - val_accuracy: 0.7765\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7921 - val_loss: 0.4706 - val_accuracy: 0.7765\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7921 - val_loss: 0.4701 - val_accuracy: 0.7765\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7921 - val_loss: 0.4695 - val_accuracy: 0.7765\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7921 - val_loss: 0.4687 - val_accuracy: 0.7765\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7921 - val_loss: 0.4659 - val_accuracy: 0.7821\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7921 - val_loss: 0.4650 - val_accuracy: 0.7821\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7921 - val_loss: 0.4653 - val_accuracy: 0.7821\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7921 - val_loss: 0.4640 - val_accuracy: 0.7821\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7921 - val_loss: 0.4647 - val_accuracy: 0.7821\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7921 - val_loss: 0.4624 - val_accuracy: 0.7821\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7921 - val_loss: 0.4620 - val_accuracy: 0.7821\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7921 - val_loss: 0.4600 - val_accuracy: 0.7821\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7921 - val_loss: 0.4608 - val_accuracy: 0.7821\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7921 - val_loss: 0.4603 - val_accuracy: 0.7821\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7893 - val_loss: 0.4602 - val_accuracy: 0.7821\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7921 - val_loss: 0.4576 - val_accuracy: 0.7821\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7921 - val_loss: 0.4575 - val_accuracy: 0.7821\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7921 - val_loss: 0.4560 - val_accuracy: 0.7821\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7907 - val_loss: 0.4563 - val_accuracy: 0.7821\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7921 - val_loss: 0.4551 - val_accuracy: 0.7821\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7921 - val_loss: 0.4577 - val_accuracy: 0.7821\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7921 - val_loss: 0.4546 - val_accuracy: 0.7821\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7907 - val_loss: 0.4563 - val_accuracy: 0.7821\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7921 - val_loss: 0.4549 - val_accuracy: 0.7821\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7921 - val_loss: 0.4568 - val_accuracy: 0.7821\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7893 - val_loss: 0.4539 - val_accuracy: 0.7821\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7879 - val_loss: 0.4563 - val_accuracy: 0.7821\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7907 - val_loss: 0.4525 - val_accuracy: 0.7821\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7921 - val_loss: 0.4545 - val_accuracy: 0.7821\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7907 - val_loss: 0.4830 - val_accuracy: 0.7765\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7865 - val_loss: 0.4575 - val_accuracy: 0.7821\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7907 - val_loss: 0.4566 - val_accuracy: 0.7821\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7907 - val_loss: 0.4580 - val_accuracy: 0.7821\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7921 - val_loss: 0.4555 - val_accuracy: 0.7821\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7921 - val_loss: 0.4538 - val_accuracy: 0.7821\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7921 - val_loss: 0.4522 - val_accuracy: 0.7821\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7907 - val_loss: 0.4519 - val_accuracy: 0.7821\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7921 - val_loss: 0.4518 - val_accuracy: 0.7821\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7921 - val_loss: 0.4510 - val_accuracy: 0.7821\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7921 - val_loss: 0.4508 - val_accuracy: 0.7821\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7921 - val_loss: 0.4525 - val_accuracy: 0.7821\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7893 - val_loss: 0.4502 - val_accuracy: 0.7821\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7921 - val_loss: 0.4520 - val_accuracy: 0.7821\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7893 - val_loss: 0.4505 - val_accuracy: 0.7821\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7921 - val_loss: 0.4541 - val_accuracy: 0.7821\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7879 - val_loss: 0.4514 - val_accuracy: 0.7821\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7921 - val_loss: 0.4490 - val_accuracy: 0.7821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f32e2ef8c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJci5rKk2PRO",
        "outputId": "582f99b6-cb44-4869-d976-5825bce9a258"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model using the Sequential API\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_3.fit(x_train, y_train,\n",
        "            validation_data=(x_test,y_test),\n",
        "            epochs=100)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 8ms/step - loss: 0.6318 - accuracy: 0.7261 - val_loss: 0.6456 - val_accuracy: 0.6872\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.7444 - val_loss: 0.6240 - val_accuracy: 0.6927\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7402 - val_loss: 0.6048 - val_accuracy: 0.7151\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.7711 - val_loss: 0.5852 - val_accuracy: 0.7263\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7739 - val_loss: 0.5605 - val_accuracy: 0.7318\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7809 - val_loss: 0.5431 - val_accuracy: 0.7654\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7949 - val_loss: 0.5309 - val_accuracy: 0.7821\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7978 - val_loss: 0.5208 - val_accuracy: 0.7933\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7992 - val_loss: 0.5152 - val_accuracy: 0.7933\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7992 - val_loss: 0.5096 - val_accuracy: 0.7933\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.8006 - val_loss: 0.5039 - val_accuracy: 0.7989\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.8006 - val_loss: 0.4981 - val_accuracy: 0.7989\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.8020 - val_loss: 0.4931 - val_accuracy: 0.7989\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8020 - val_loss: 0.4891 - val_accuracy: 0.7989\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8020 - val_loss: 0.4851 - val_accuracy: 0.7989\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8034 - val_loss: 0.4823 - val_accuracy: 0.7933\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8062 - val_loss: 0.4788 - val_accuracy: 0.7933\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8048 - val_loss: 0.4748 - val_accuracy: 0.7933\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8062 - val_loss: 0.4720 - val_accuracy: 0.7933\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8062 - val_loss: 0.4694 - val_accuracy: 0.7933\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.8062 - val_loss: 0.4661 - val_accuracy: 0.7933\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.8062 - val_loss: 0.4635 - val_accuracy: 0.7933\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8062 - val_loss: 0.4617 - val_accuracy: 0.7933\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8062 - val_loss: 0.4594 - val_accuracy: 0.7933\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8076 - val_loss: 0.4575 - val_accuracy: 0.7933\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8090 - val_loss: 0.4552 - val_accuracy: 0.7933\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8104 - val_loss: 0.4544 - val_accuracy: 0.7933\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8104 - val_loss: 0.4523 - val_accuracy: 0.7933\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8090 - val_loss: 0.4506 - val_accuracy: 0.7933\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8104 - val_loss: 0.4501 - val_accuracy: 0.7933\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8118 - val_loss: 0.4490 - val_accuracy: 0.7933\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8104 - val_loss: 0.4465 - val_accuracy: 0.7933\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8118 - val_loss: 0.4457 - val_accuracy: 0.7933\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8118 - val_loss: 0.4446 - val_accuracy: 0.7933\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8118 - val_loss: 0.4450 - val_accuracy: 0.7933\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8118 - val_loss: 0.4432 - val_accuracy: 0.7933\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8118 - val_loss: 0.4423 - val_accuracy: 0.7933\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.8118 - val_loss: 0.4419 - val_accuracy: 0.7933\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8104 - val_loss: 0.4424 - val_accuracy: 0.7933\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8146 - val_loss: 0.4407 - val_accuracy: 0.7933\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8146 - val_loss: 0.4399 - val_accuracy: 0.7933\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8174 - val_loss: 0.4377 - val_accuracy: 0.7989\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8188 - val_loss: 0.4379 - val_accuracy: 0.7933\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.8188 - val_loss: 0.4383 - val_accuracy: 0.7877\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8160 - val_loss: 0.4389 - val_accuracy: 0.7933\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8090 - val_loss: 0.4390 - val_accuracy: 0.7933\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8188 - val_loss: 0.4375 - val_accuracy: 0.7989\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8188 - val_loss: 0.4378 - val_accuracy: 0.7989\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8188 - val_loss: 0.4378 - val_accuracy: 0.7989\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8202 - val_loss: 0.4365 - val_accuracy: 0.7989\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8188 - val_loss: 0.4369 - val_accuracy: 0.7989\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8188 - val_loss: 0.4364 - val_accuracy: 0.7989\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8188 - val_loss: 0.4355 - val_accuracy: 0.7989\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8188 - val_loss: 0.4354 - val_accuracy: 0.7989\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8188 - val_loss: 0.4362 - val_accuracy: 0.7989\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8188 - val_loss: 0.4360 - val_accuracy: 0.7989\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8188 - val_loss: 0.4364 - val_accuracy: 0.7989\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8188 - val_loss: 0.4350 - val_accuracy: 0.7989\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8188 - val_loss: 0.4360 - val_accuracy: 0.7989\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8202 - val_loss: 0.4357 - val_accuracy: 0.7989\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8188 - val_loss: 0.4357 - val_accuracy: 0.7989\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8216 - val_loss: 0.4360 - val_accuracy: 0.7989\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8174 - val_loss: 0.4378 - val_accuracy: 0.7989\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8188 - val_loss: 0.4387 - val_accuracy: 0.7989\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8188 - val_loss: 0.4367 - val_accuracy: 0.7989\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8216 - val_loss: 0.4361 - val_accuracy: 0.7989\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8202 - val_loss: 0.4370 - val_accuracy: 0.7989\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8202 - val_loss: 0.4366 - val_accuracy: 0.7989\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8202 - val_loss: 0.4365 - val_accuracy: 0.7989\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8216 - val_loss: 0.4370 - val_accuracy: 0.7989\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8202 - val_loss: 0.4361 - val_accuracy: 0.7989\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8202 - val_loss: 0.4358 - val_accuracy: 0.7989\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8202 - val_loss: 0.4353 - val_accuracy: 0.7989\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8202 - val_loss: 0.4369 - val_accuracy: 0.7989\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8202 - val_loss: 0.4361 - val_accuracy: 0.7989\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8202 - val_loss: 0.4361 - val_accuracy: 0.7989\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8174 - val_loss: 0.4359 - val_accuracy: 0.7989\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8244 - val_loss: 0.4366 - val_accuracy: 0.7989\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8230 - val_loss: 0.4347 - val_accuracy: 0.7989\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8160 - val_loss: 0.4366 - val_accuracy: 0.7989\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8202 - val_loss: 0.4356 - val_accuracy: 0.7989\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8174 - val_loss: 0.4377 - val_accuracy: 0.7989\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8258 - val_loss: 0.4361 - val_accuracy: 0.7989\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8174 - val_loss: 0.4366 - val_accuracy: 0.7989\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8230 - val_loss: 0.4364 - val_accuracy: 0.7989\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8244 - val_loss: 0.4356 - val_accuracy: 0.7989\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8230 - val_loss: 0.4362 - val_accuracy: 0.7989\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8188 - val_loss: 0.4369 - val_accuracy: 0.7989\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8230 - val_loss: 0.4353 - val_accuracy: 0.7989\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8230 - val_loss: 0.4368 - val_accuracy: 0.7989\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8104 - val_loss: 0.4375 - val_accuracy: 0.7989\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8202 - val_loss: 0.4396 - val_accuracy: 0.7989\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8272 - val_loss: 0.4355 - val_accuracy: 0.7933\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8258 - val_loss: 0.4368 - val_accuracy: 0.7989\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8174 - val_loss: 0.4370 - val_accuracy: 0.7989\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8230 - val_loss: 0.4357 - val_accuracy: 0.7933\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8216 - val_loss: 0.4362 - val_accuracy: 0.7989\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8230 - val_loss: 0.4361 - val_accuracy: 0.7989\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8244 - val_loss: 0.4365 - val_accuracy: 0.7989\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8174 - val_loss: 0.4373 - val_accuracy: 0.7989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f32e55e6e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k80xM8jsAlRr",
        "outputId": "226bb4dd-5998-4b18-dd91-b416954c28e9"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model using the Sequential API\n",
        "model_4 = tf.keras.Sequential([\n",
        "  #tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_4.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Create a learning rate scheduler callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # traverse a set of learning rate values starting from 1e-4, increasing by 10**(epoch/20) every epoch\n",
        "\n",
        "# Fit the model (passing the lr_scheduler callback)\n",
        "history_4 = model_4.fit(x_train, y_train,\n",
        "            validation_data=(x_test,y_test),\n",
        "            callbacks=[lr_scheduler],\n",
        "            epochs=50)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "23/23 [==============================] - 1s 8ms/step - loss: 0.7890 - accuracy: 0.3272 - val_loss: 0.7979 - val_accuracy: 0.3296\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7844 - accuracy: 0.3287 - val_loss: 0.7936 - val_accuracy: 0.3296\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.7795 - accuracy: 0.3315 - val_loss: 0.7888 - val_accuracy: 0.3296\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7741 - accuracy: 0.3385 - val_loss: 0.7838 - val_accuracy: 0.3296\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7684 - accuracy: 0.3385 - val_loss: 0.7785 - val_accuracy: 0.3240\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7626 - accuracy: 0.3385 - val_loss: 0.7727 - val_accuracy: 0.3296\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.7561 - accuracy: 0.3371 - val_loss: 0.7664 - val_accuracy: 0.3296\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.7491 - accuracy: 0.3371 - val_loss: 0.7596 - val_accuracy: 0.3296\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.3399 - val_loss: 0.7526 - val_accuracy: 0.3631\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.3666 - val_loss: 0.7464 - val_accuracy: 0.3631\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7287 - accuracy: 0.3708 - val_loss: 0.7420 - val_accuracy: 0.3631\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7238 - accuracy: 0.3876 - val_loss: 0.7371 - val_accuracy: 0.3911\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7183 - accuracy: 0.4059 - val_loss: 0.7318 - val_accuracy: 0.3911\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7117 - accuracy: 0.4888 - val_loss: 0.7250 - val_accuracy: 0.5642\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.7039 - accuracy: 0.5716 - val_loss: 0.7173 - val_accuracy: 0.5642\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5758 - val_loss: 0.7083 - val_accuracy: 0.6034\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.6390 - val_loss: 0.6976 - val_accuracy: 0.6089\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.6531 - val_loss: 0.6853 - val_accuracy: 0.6201\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6615 - val_loss: 0.6722 - val_accuracy: 0.6201\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6756 - val_loss: 0.6588 - val_accuracy: 0.6369\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.6657 - val_loss: 0.6441 - val_accuracy: 0.6201\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6657 - val_loss: 0.6296 - val_accuracy: 0.6201\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.6685 - val_loss: 0.6160 - val_accuracy: 0.6257\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.6699 - val_loss: 0.6018 - val_accuracy: 0.6257\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.6952 - val_loss: 0.5865 - val_accuracy: 0.6480\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7233 - val_loss: 0.5730 - val_accuracy: 0.6872\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7542 - val_loss: 0.5586 - val_accuracy: 0.6927\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7753 - val_loss: 0.5449 - val_accuracy: 0.7318\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7837 - val_loss: 0.5334 - val_accuracy: 0.7318\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7851 - val_loss: 0.5203 - val_accuracy: 0.7263\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7921 - val_loss: 0.5028 - val_accuracy: 0.7821\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7978 - val_loss: 0.4847 - val_accuracy: 0.7877\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.8020 - val_loss: 0.4709 - val_accuracy: 0.7877\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.8034 - val_loss: 0.4617 - val_accuracy: 0.7821\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7978 - val_loss: 0.4584 - val_accuracy: 0.7877\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.8104 - val_loss: 0.4540 - val_accuracy: 0.7877\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8076 - val_loss: 0.4504 - val_accuracy: 0.7877\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8118 - val_loss: 0.4477 - val_accuracy: 0.7877\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8090 - val_loss: 0.4433 - val_accuracy: 0.7933\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8048 - val_loss: 0.4472 - val_accuracy: 0.7877\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8118 - val_loss: 0.4371 - val_accuracy: 0.7933\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8076 - val_loss: 0.4384 - val_accuracy: 0.7933\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8118 - val_loss: 0.4362 - val_accuracy: 0.7989\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8104 - val_loss: 0.4355 - val_accuracy: 0.7989\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8104 - val_loss: 0.4317 - val_accuracy: 0.7933\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8146 - val_loss: 0.4347 - val_accuracy: 0.7933\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8104 - val_loss: 0.4323 - val_accuracy: 0.7933\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8062 - val_loss: 0.4261 - val_accuracy: 0.7989\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8104 - val_loss: 0.4304 - val_accuracy: 0.7933\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8034 - val_loss: 0.4358 - val_accuracy: 0.7933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "el2eexb3AlYU",
        "outputId": "ca75625f-5d30-4dd7-8e0d-b1acfbcf67e7"
      },
      "source": [
        "# Checkout the history\n",
        "pd.DataFrame(history_4.history).plot(figsize=(10,7), xlabel=\"epochs\");"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic8d15sGAlab",
        "outputId": "b37d0026-50b8-4df6-83a6-ac9297a8e8ec"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model using the Sequential API\n",
        "model_5 = tf.keras.Sequential([\n",
        "  #tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_5.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n",
        "                optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Create a learning rate scheduler callback\n",
        "#lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # traverse a set of learning rate values starting from 1e-4, increasing by 10**(epoch/20) every epoch\n",
        "\n",
        "# Fit the model (passing the lr_scheduler callback)\n",
        "history_5 = model_4.fit(x_train, y_train,\n",
        "            validation_data=(x_test,y_test),\n",
        "           # callbacks=[lr_scheduler],\n",
        "            epochs=50)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.8118 - val_loss: 0.4398 - val_accuracy: 0.7989\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8104 - val_loss: 0.4221 - val_accuracy: 0.7989\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8104 - val_loss: 0.4262 - val_accuracy: 0.7989\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8090 - val_loss: 0.4311 - val_accuracy: 0.7989\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8020 - val_loss: 0.4348 - val_accuracy: 0.7933\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8062 - val_loss: 0.4360 - val_accuracy: 0.7933\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8160 - val_loss: 0.4381 - val_accuracy: 0.7877\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8062 - val_loss: 0.4363 - val_accuracy: 0.7989\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8132 - val_loss: 0.4384 - val_accuracy: 0.7877\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8118 - val_loss: 0.4295 - val_accuracy: 0.7877\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8146 - val_loss: 0.4334 - val_accuracy: 0.7933\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8062 - val_loss: 0.4353 - val_accuracy: 0.7933\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8062 - val_loss: 0.4420 - val_accuracy: 0.7821\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8076 - val_loss: 0.4327 - val_accuracy: 0.7933\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8090 - val_loss: 0.4400 - val_accuracy: 0.7877\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.8216 - val_loss: 0.4354 - val_accuracy: 0.7933\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8160 - val_loss: 0.4563 - val_accuracy: 0.7933\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8132 - val_loss: 0.4333 - val_accuracy: 0.7989\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8174 - val_loss: 0.4344 - val_accuracy: 0.7989\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8034 - val_loss: 0.4375 - val_accuracy: 0.7989\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8118 - val_loss: 0.4487 - val_accuracy: 0.7989\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8104 - val_loss: 0.4463 - val_accuracy: 0.7989\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8146 - val_loss: 0.4335 - val_accuracy: 0.7989\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8062 - val_loss: 0.4328 - val_accuracy: 0.7989\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8160 - val_loss: 0.4343 - val_accuracy: 0.7989\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8160 - val_loss: 0.4391 - val_accuracy: 0.7933\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8090 - val_loss: 0.4343 - val_accuracy: 0.7821\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8132 - val_loss: 0.4342 - val_accuracy: 0.7877\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8174 - val_loss: 0.4635 - val_accuracy: 0.7989\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.8034 - val_loss: 0.4378 - val_accuracy: 0.7989\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8034 - val_loss: 0.4278 - val_accuracy: 0.7933\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8132 - val_loss: 0.4324 - val_accuracy: 0.7933\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8090 - val_loss: 0.4309 - val_accuracy: 0.7933\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8174 - val_loss: 0.4463 - val_accuracy: 0.7989\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8034 - val_loss: 0.4290 - val_accuracy: 0.7989\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8104 - val_loss: 0.4347 - val_accuracy: 0.8045\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8090 - val_loss: 0.4311 - val_accuracy: 0.7989\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8188 - val_loss: 0.4267 - val_accuracy: 0.7989\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.8076 - val_loss: 0.4280 - val_accuracy: 0.8045\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7963 - val_loss: 0.4419 - val_accuracy: 0.8045\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8118 - val_loss: 0.4317 - val_accuracy: 0.8101\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.8076 - val_loss: 0.4280 - val_accuracy: 0.7933\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8174 - val_loss: 0.4317 - val_accuracy: 0.7933\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8230 - val_loss: 0.4269 - val_accuracy: 0.7933\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8174 - val_loss: 0.4291 - val_accuracy: 0.7933\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8076 - val_loss: 0.4221 - val_accuracy: 0.8045\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8160 - val_loss: 0.4281 - val_accuracy: 0.7989\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8174 - val_loss: 0.4232 - val_accuracy: 0.8045\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8146 - val_loss: 0.4367 - val_accuracy: 0.7933\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8034 - val_loss: 0.4359 - val_accuracy: 0.7989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_5HEzOOCk7O",
        "outputId": "38cf96b0-db43-474a-e06b-b5f58de1d5df"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  #tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_6.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n",
        "                optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Create a learning rate scheduler callback\n",
        "#lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # traverse a set of learning rate values starting from 1e-4, increasing by 10**(epoch/20) every epoch\n",
        "\n",
        "# Fit the model (passing the lr_scheduler callback)\n",
        "history_6 = model_6.fit(x_train, y_train,\n",
        "            validation_data=(x_test,y_test),\n",
        "            #callbacks=[lr_scheduler],\n",
        "            epochs=10)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "23/23 [==============================] - 1s 8ms/step - loss: 0.5883 - accuracy: 0.6657 - val_loss: 0.5276 - val_accuracy: 0.7933\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7992 - val_loss: 0.4838 - val_accuracy: 0.7933\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7935 - val_loss: 0.4762 - val_accuracy: 0.7877\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7935 - val_loss: 0.4484 - val_accuracy: 0.7933\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.8076 - val_loss: 0.4485 - val_accuracy: 0.7933\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7823 - val_loss: 0.4379 - val_accuracy: 0.7989\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.8090 - val_loss: 0.4572 - val_accuracy: 0.7821\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8020 - val_loss: 0.4485 - val_accuracy: 0.7989\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7992 - val_loss: 0.4459 - val_accuracy: 0.7933\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8188 - val_loss: 0.4280 - val_accuracy: 0.8045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wgHs1faDTed",
        "outputId": "a096322a-32eb-4215-eebf-e8bd01e191ba"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model using the Sequential API\n",
        "model_7 = tf.keras.Sequential([\n",
        "  #tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  #tf.keras.layers.Dense(1, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_7.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n",
        "                optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Create a learning rate scheduler callback\n",
        "#lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # traverse a set of learning rate values starting from 1e-4, increasing by 10**(epoch/20) every epoch\n",
        "\n",
        "# Fit the model (passing the lr_scheduler callback)\n",
        "history_7 = model_7.fit(x_train, y_train,\n",
        "            validation_data=(x_test,y_test),\n",
        "            #callbacks=[lr_scheduler],\n",
        "            epochs=10)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "23/23 [==============================] - 1s 9ms/step - loss: 0.5883 - accuracy: 0.6657 - val_loss: 0.5276 - val_accuracy: 0.7933\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7992 - val_loss: 0.4838 - val_accuracy: 0.7933\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7935 - val_loss: 0.4762 - val_accuracy: 0.7877\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7935 - val_loss: 0.4484 - val_accuracy: 0.7933\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.8076 - val_loss: 0.4485 - val_accuracy: 0.7933\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7823 - val_loss: 0.4379 - val_accuracy: 0.7989\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.8090 - val_loss: 0.4572 - val_accuracy: 0.7821\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8020 - val_loss: 0.4485 - val_accuracy: 0.7989\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7992 - val_loss: 0.4459 - val_accuracy: 0.7933\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8188 - val_loss: 0.4280 - val_accuracy: 0.8045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ5yaDTbDThB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train1, x_test1, y_train1, y_test1 = train_test_split(x, \n",
        "                                                    y, \n",
        "                                                    test_size=0.1, \n",
        "                                                    random_state=42)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXWVIpueDTjW",
        "outputId": "e262b08b-5e30-41ae-c430-9f17fb1d9b63"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model using the Sequential API\n",
        "model_8 = tf.keras.Sequential([\n",
        "  #tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  #tf.keras.layers.Dense(1, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_8.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n",
        "                optimizer=tf.keras.optimizers.Adam(0.02),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Create a learning rate scheduler callback\n",
        "#lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # traverse a set of learning rate values starting from 1e-4, increasing by 10**(epoch/20) every epoch\n",
        "\n",
        "# Fit the model (passing the lr_scheduler callback)\n",
        "history_8 = model_8.fit(x_train1, y_train1,\n",
        "            validation_data=(x_test1,y_test1),\n",
        "            #callbacks=[lr_scheduler],\n",
        "            epochs=10)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "26/26 [==============================] - 1s 7ms/step - loss: 0.5922 - accuracy: 0.6704 - val_loss: 0.5308 - val_accuracy: 0.7667\n",
            "Epoch 2/10\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7903 - val_loss: 0.4924 - val_accuracy: 0.8111\n",
            "Epoch 3/10\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7878 - val_loss: 0.4732 - val_accuracy: 0.8000\n",
            "Epoch 4/10\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7915 - val_loss: 0.4738 - val_accuracy: 0.8111\n",
            "Epoch 5/10\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7890 - val_loss: 0.4685 - val_accuracy: 0.8222\n",
            "Epoch 6/10\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7965 - val_loss: 0.4445 - val_accuracy: 0.8111\n",
            "Epoch 7/10\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7928 - val_loss: 0.4630 - val_accuracy: 0.8222\n",
            "Epoch 8/10\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8027 - val_loss: 0.4366 - val_accuracy: 0.8222\n",
            "Epoch 9/10\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8065 - val_loss: 0.4220 - val_accuracy: 0.8222\n",
            "Epoch 10/10\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7965 - val_loss: 0.4230 - val_accuracy: 0.8222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3xCjBe60HN83",
        "outputId": "08239f5e-638e-4e9d-ab21-756267def922"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass     Sex  SibSp  Parch Embarked\n",
              "0         0       3    male      1      0        S\n",
              "1         1       1  female      1      0        C\n",
              "2         1       3  female      0      0        S\n",
              "3         1       1  female      1      0        S\n",
              "4         0       3    male      0      0        S"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-7XcZmSDTlO"
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# Create column transformer (this will help us normalize/preprocess our data)\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"Pclass\", \"SibSp\", \"Parch\"]), # get all values between 0 and 1\n",
        "    (OneHotEncoder(), [\"Sex\", \"Embarked\"])\n",
        ")\n",
        "\n",
        "# Create X & y\n",
        "x2 = train_df.drop(\"Survived\", axis=1)\n",
        "y2 = train_df['Survived']\n",
        "\n",
        "# Build our train and test sets (use random state to ensure same split as before)\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.1, random_state=42)\n",
        "\n",
        "# Fit column transformer on the training data only (doing so on test data would result in data leakage)\n",
        "ct.fit(x2_train)\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n",
        "x2_train_normal = ct.transform(x2_train)\n",
        "x2_test_normal = ct.transform(x2_test)"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "oJxOJRrKLPwV",
        "outputId": "93fb9fcf-3ee0-4254-e9b3-9be10195fc52"
      },
      "source": [
        "x2_test"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>709</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>2</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>822</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass     Sex  SibSp  Parch Embarked\n",
              "709       3    male      1      1        C\n",
              "439       2    male      0      0        S\n",
              "840       3    male      0      0        S\n",
              "720       2  female      0      1        S\n",
              "39        3  female      1      0        C\n",
              "..      ...     ...    ...    ...      ...\n",
              "493       1    male      0      0        C\n",
              "215       1  female      1      0        C\n",
              "309       1  female      0      0        C\n",
              "822       1    male      0      0        S\n",
              "250       3    male      0      0        S\n",
              "\n",
              "[90 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZGe60JGI6CS",
        "outputId": "8a8eac0f-c545-40cf-d219-f4e22146802a"
      },
      "source": [
        "x2_test_normal.shape"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDBFmkeZKmFf",
        "outputId": "644b5e2b-8e87-452b-a1bf-c529c15b6e43"
      },
      "source": [
        "x2_test_normal = tf.convert_to_tensor(x2_test_normal, np.float32)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(90, 8), dtype=float32, numpy=\n",
              "array([[1.        , 0.125     , 0.16666667, 0.        , 1.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.5       , 0.        , 0.16666667, 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.125     , 0.        , 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 1.        , 0.        ],\n",
              "       [1.        , 0.25      , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 1.        , 0.        ],\n",
              "       [0.        , 0.        , 0.33333334, 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.125     , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.375     , 0.16666667, 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.        , 0.16666667, 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.125     , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 1.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.125     , 0.        , 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.375     , 0.33333334, 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.375     , 0.33333334, 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.125     , 0.        , 0.        , 1.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 1.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.5       , 0.25      , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.125     , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 1.        , 0.        ],\n",
              "       [1.        , 0.        , 0.16666667, 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.125     , 0.5       , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.        , 0.33333334, 0.        , 1.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.25      , 0.16666667, 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.        , 0.125     , 0.16666667, 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.125     , 0.6666667 , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.125     , 0.33333334, 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 1.        , 0.        ],\n",
              "       [0.        , 0.        , 0.33333334, 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.        , 0.16666667, 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 1.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.5       , 0.        , 0.16666667, 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.5       , 0.125     , 0.        , 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 1.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.125     , 0.16666667, 0.        , 1.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.        , 0.125     , 0.        , 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.5       , 0.125     , 0.16666667, 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.25      , 0.33333334, 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.        , 0.125     , 0.16666667, 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.125     , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 1.        , 0.        ],\n",
              "       [0.        , 0.        , 0.33333334, 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.33333334, 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.5       , 0.16666667, 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.5       , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.125     , 0.16666667, 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 1.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.        , 0.125     , 0.        , 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "        0.        , 0.        , 1.        ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WBeOZOQK-7e"
      },
      "source": [
        "x2_train_normal = tf.convert_to_tensor(x2_train_normal, np.float32)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No0y4y3cDToL",
        "outputId": "71d2aec0-9eb7-400f-9bb3-712b5cbc64bf"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model using the Sequential API\n",
        "model_9 = tf.keras.Sequential([\n",
        "  #tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1000, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        " #tf.keras.layers.Dense(1, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_9.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n",
        "                optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Fit the model (passing the lr_scheduler callback)\n",
        "history_9 = model_9.fit(x2_train_normal, y2_train,\n",
        "            validation_data=(x2_test_normal,y2_test),\n",
        "            #callbacks=[lr_scheduler],\n",
        "            epochs=14)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/14\n",
            "26/26 [==============================] - 1s 9ms/step - loss: 0.5430 - accuracy: 0.7678 - val_loss: 0.4129 - val_accuracy: 0.8222\n",
            "Epoch 2/14\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8040 - val_loss: 0.4417 - val_accuracy: 0.8222\n",
            "Epoch 3/14\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.8140 - val_loss: 0.4874 - val_accuracy: 0.8111\n",
            "Epoch 4/14\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.8015 - val_loss: 0.4166 - val_accuracy: 0.8333\n",
            "Epoch 5/14\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7953 - val_loss: 0.4199 - val_accuracy: 0.8222\n",
            "Epoch 6/14\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.8065 - val_loss: 0.4072 - val_accuracy: 0.8333\n",
            "Epoch 7/14\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8040 - val_loss: 0.4484 - val_accuracy: 0.8222\n",
            "Epoch 8/14\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.8077 - val_loss: 0.4157 - val_accuracy: 0.8222\n",
            "Epoch 9/14\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8065 - val_loss: 0.4190 - val_accuracy: 0.8111\n",
            "Epoch 10/14\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8052 - val_loss: 0.3957 - val_accuracy: 0.8111\n",
            "Epoch 11/14\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.8090 - val_loss: 0.4299 - val_accuracy: 0.8333\n",
            "Epoch 12/14\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.8190 - val_loss: 0.4081 - val_accuracy: 0.8333\n",
            "Epoch 13/14\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8115 - val_loss: 0.4319 - val_accuracy: 0.8111\n",
            "Epoch 14/14\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8102 - val_loss: 0.4310 - val_accuracy: 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "TkZHChH3DTr1",
        "outputId": "cc08e28a-314e-4f49-f71c-72962d70a019"
      },
      "source": [
        "test_df = pd.read_csv('test.csv')\n",
        "test_df"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1305</td>\n",
              "      <td>3</td>\n",
              "      <td>Spector, Mr. Woolf</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A.5. 3236</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1306</td>\n",
              "      <td>1</td>\n",
              "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17758</td>\n",
              "      <td>108.9000</td>\n",
              "      <td>C105</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>1307</td>\n",
              "      <td>3</td>\n",
              "      <td>Saether, Mr. Simon Sivertsen</td>\n",
              "      <td>male</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>SOTON/O.Q. 3101262</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>1308</td>\n",
              "      <td>3</td>\n",
              "      <td>Ware, Mr. Frederick</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>359309</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1309</td>\n",
              "      <td>3</td>\n",
              "      <td>Peter, Master. Michael J</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2668</td>\n",
              "      <td>22.3583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Pclass  ... Cabin Embarked\n",
              "0            892       3  ...   NaN        Q\n",
              "1            893       3  ...   NaN        S\n",
              "2            894       2  ...   NaN        Q\n",
              "3            895       3  ...   NaN        S\n",
              "4            896       3  ...   NaN        S\n",
              "..           ...     ...  ...   ...      ...\n",
              "413         1305       3  ...   NaN        S\n",
              "414         1306       1  ...  C105        C\n",
              "415         1307       3  ...   NaN        S\n",
              "416         1308       3  ...   NaN        S\n",
              "417         1309       3  ...   NaN        C\n",
              "\n",
              "[418 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Mma3QajuDTul",
        "outputId": "95b4965b-8682-49ce-928a-6b25e84c21d4"
      },
      "source": [
        "test_df = test_df.drop(columns=['Cabin','Age','Name','Ticket','Fare','PassengerId'])\n",
        "test_df"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass     Sex  SibSp  Parch Embarked\n",
              "0         3    male      0      0        Q\n",
              "1         3  female      1      0        S\n",
              "2         2    male      0      0        Q\n",
              "3         3    male      0      0        S\n",
              "4         3  female      1      1        S\n",
              "..      ...     ...    ...    ...      ...\n",
              "413       3    male      0      0        S\n",
              "414       1  female      0      0        C\n",
              "415       3    male      0      0        S\n",
              "416       3    male      0      0        S\n",
              "417       3    male      1      1        C\n",
              "\n",
              "[418 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ta4Mt8rDTwt",
        "outputId": "7ddc0d9e-9d43-4a87-a0a5-19cc1b007f66"
      },
      "source": [
        "test_df.isna().sum()"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pclass      0\n",
              "Sex         0\n",
              "SibSp       0\n",
              "Parch       0\n",
              "Embarked    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tndlpqANmuj",
        "outputId": "e38309f9-1b2b-48b5-d20f-4a31220445df"
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# Create column transformer (this will help us normalize/preprocess our data)\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"Pclass\", \"SibSp\", \"Parch\"]), # get all values between 0 and 1\n",
        "    (OneHotEncoder(), [\"Sex\", \"Embarked\"])\n",
        ")\n",
        "x3 = test_df\n",
        "\n",
        "# Fit column transformer on the training data only (doing so on test data would result in data leakage)\n",
        "ct.fit(x3)\n",
        "# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n",
        "x3_normal = ct.transform(x3)\n",
        "x3_normal"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
              "        0.        ],\n",
              "       [1.        , 0.125     , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.5       , 0.        , 0.        , ..., 0.        , 1.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [1.        , 0.125     , 0.11111111, ..., 1.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmVZi3YaN1HI",
        "outputId": "1a59a585-7994-4ab6-c656-13b76aa00da8"
      },
      "source": [
        "pred_probs = model_9.predict(x3_normal)\n",
        "pred_probs"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.07336649],\n",
              "       [0.41939777],\n",
              "       [0.10486978],\n",
              "       [0.09197676],\n",
              "       [0.4400853 ],\n",
              "       [0.09197676],\n",
              "       [0.8266395 ],\n",
              "       [0.23677695],\n",
              "       [0.7105144 ],\n",
              "       [0.1004509 ],\n",
              "       [0.09197676],\n",
              "       [0.26794666],\n",
              "       [0.9939499 ],\n",
              "       [0.16409877],\n",
              "       [0.9939499 ],\n",
              "       [0.9362874 ],\n",
              "       [0.10486978],\n",
              "       [0.3128388 ],\n",
              "       [0.41939777],\n",
              "       [0.7105144 ],\n",
              "       [0.48788133],\n",
              "       [0.13806659],\n",
              "       [0.9950147 ],\n",
              "       [0.48975205],\n",
              "       [0.98773843],\n",
              "       [0.09731644],\n",
              "       [0.9916959 ],\n",
              "       [0.3128388 ],\n",
              "       [0.26794666],\n",
              "       [0.29725543],\n",
              "       [0.16409877],\n",
              "       [0.17008081],\n",
              "       [0.43557566],\n",
              "       [0.43557566],\n",
              "       [0.48788133],\n",
              "       [0.3128388 ],\n",
              "       [0.46909407],\n",
              "       [0.46909407],\n",
              "       [0.09197676],\n",
              "       [0.09197676],\n",
              "       [0.36065805],\n",
              "       [0.26794666],\n",
              "       [0.09197676],\n",
              "       [0.9547468 ],\n",
              "       [0.9939499 ],\n",
              "       [0.09197676],\n",
              "       [0.48529962],\n",
              "       [0.07336649],\n",
              "       [0.992412  ],\n",
              "       [0.61253023],\n",
              "       [0.28654906],\n",
              "       [0.40365955],\n",
              "       [0.9199263 ],\n",
              "       [0.9911718 ],\n",
              "       [0.40365955],\n",
              "       [0.04868689],\n",
              "       [0.09197676],\n",
              "       [0.09197676],\n",
              "       [0.09731644],\n",
              "       [0.992412  ],\n",
              "       [0.09197676],\n",
              "       [0.15465143],\n",
              "       [0.09197676],\n",
              "       [0.8266395 ],\n",
              "       [0.49070302],\n",
              "       [0.9547468 ],\n",
              "       [0.8266395 ],\n",
              "       [0.26794666],\n",
              "       [0.48529962],\n",
              "       [0.99245214],\n",
              "       [0.8266395 ],\n",
              "       [0.09197676],\n",
              "       [0.46909407],\n",
              "       [0.48529962],\n",
              "       [0.992412  ],\n",
              "       [0.48529962],\n",
              "       [0.09197676],\n",
              "       [0.9923897 ],\n",
              "       [0.15465143],\n",
              "       [0.8266395 ],\n",
              "       [0.34221566],\n",
              "       [0.28654906],\n",
              "       [0.26794666],\n",
              "       [0.09197676],\n",
              "       [0.10486978],\n",
              "       [0.31632674],\n",
              "       [0.8266395 ],\n",
              "       [0.46909407],\n",
              "       [0.8266395 ],\n",
              "       [0.23677695],\n",
              "       [0.41939777],\n",
              "       [0.09197676],\n",
              "       [0.992881  ],\n",
              "       [0.09197676],\n",
              "       [0.48529962],\n",
              "       [0.09197676],\n",
              "       [0.9939499 ],\n",
              "       [0.09197676],\n",
              "       [0.46909407],\n",
              "       [0.09197676],\n",
              "       [0.9905518 ],\n",
              "       [0.16409877],\n",
              "       [0.07336649],\n",
              "       [0.09197676],\n",
              "       [0.6612104 ],\n",
              "       [0.09197676],\n",
              "       [0.07336649],\n",
              "       [0.07336649],\n",
              "       [0.09197676],\n",
              "       [0.15465143],\n",
              "       [0.40365955],\n",
              "       [0.8266395 ],\n",
              "       [0.992412  ],\n",
              "       [0.8266395 ],\n",
              "       [0.9939499 ],\n",
              "       [0.31632674],\n",
              "       [0.3128388 ],\n",
              "       [0.4400853 ],\n",
              "       [0.48529962],\n",
              "       [0.932037  ],\n",
              "       [0.9547468 ],\n",
              "       [0.08724818],\n",
              "       [0.9905518 ],\n",
              "       [0.09197676],\n",
              "       [0.07336649],\n",
              "       [0.5404689 ],\n",
              "       [0.09197676],\n",
              "       [0.8129226 ],\n",
              "       [0.15465143],\n",
              "       [0.09197676],\n",
              "       [0.09197676],\n",
              "       [0.48529962],\n",
              "       [0.6570349 ],\n",
              "       [0.31632674],\n",
              "       [0.09197676],\n",
              "       [0.09197676],\n",
              "       [0.3128388 ],\n",
              "       [0.15465143],\n",
              "       [0.46909407],\n",
              "       [0.1135751 ],\n",
              "       [0.0995248 ],\n",
              "       [0.9950147 ],\n",
              "       [0.4947792 ],\n",
              "       [0.15465143],\n",
              "       [0.26794666],\n",
              "       [0.10043535],\n",
              "       [0.26794666],\n",
              "       [0.09197676],\n",
              "       [0.26794666],\n",
              "       [0.23677695],\n",
              "       [0.9916959 ],\n",
              "       [0.3128388 ],\n",
              "       [0.09197676],\n",
              "       [0.61253023],\n",
              "       [0.0923962 ],\n",
              "       [0.09197676],\n",
              "       [0.9950147 ],\n",
              "       [0.46909407],\n",
              "       [0.2679466 ],\n",
              "       [0.61253023],\n",
              "       [0.8266395 ],\n",
              "       [0.34221566],\n",
              "       [0.9547468 ],\n",
              "       [0.09197676],\n",
              "       [0.15465143],\n",
              "       [0.4400853 ],\n",
              "       [0.48529962],\n",
              "       [0.17834553],\n",
              "       [0.992412  ],\n",
              "       [0.46909407],\n",
              "       [0.09197676],\n",
              "       [0.3128388 ],\n",
              "       [0.09731644],\n",
              "       [0.3128388 ],\n",
              "       [0.1692822 ],\n",
              "       [0.96142143],\n",
              "       [0.9547468 ],\n",
              "       [0.48788133],\n",
              "       [0.95917773],\n",
              "       [0.9909141 ],\n",
              "       [0.15465143],\n",
              "       [0.4887175 ],\n",
              "       [0.9939499 ],\n",
              "       [0.07336649],\n",
              "       [0.9897622 ],\n",
              "       [0.15465143],\n",
              "       [0.9611631 ],\n",
              "       [0.1004509 ],\n",
              "       [0.02369463],\n",
              "       [0.15465143],\n",
              "       [0.16409877],\n",
              "       [0.2679466 ],\n",
              "       [0.14650193],\n",
              "       [0.10486978],\n",
              "       [0.30037108],\n",
              "       [0.09197676],\n",
              "       [0.4913511 ],\n",
              "       [0.46909407],\n",
              "       [0.15465143],\n",
              "       [0.46909407],\n",
              "       [0.8266395 ],\n",
              "       [0.20063901],\n",
              "       [0.48788133],\n",
              "       [0.94549483],\n",
              "       [0.15465143],\n",
              "       [0.48529962],\n",
              "       [0.8266395 ],\n",
              "       [0.15465143],\n",
              "       [0.992412  ],\n",
              "       [0.09197676],\n",
              "       [0.09197676],\n",
              "       [0.09197676],\n",
              "       [0.15465143],\n",
              "       [0.932037  ],\n",
              "       [0.15706727],\n",
              "       [0.26794666],\n",
              "       [0.8266395 ],\n",
              "       [0.3705262 ],\n",
              "       [0.9897622 ],\n",
              "       [0.09197676],\n",
              "       [0.9362874 ],\n",
              "       [0.09197676],\n",
              "       [0.9547468 ],\n",
              "       [0.09197676],\n",
              "       [0.992412  ],\n",
              "       [0.7303381 ],\n",
              "       [0.09197676],\n",
              "       [0.8266395 ],\n",
              "       [0.09197676],\n",
              "       [0.15465143],\n",
              "       [0.15465143],\n",
              "       [0.9950147 ],\n",
              "       [0.09731644],\n",
              "       [0.07336649],\n",
              "       [0.48788133],\n",
              "       [0.09197676],\n",
              "       [0.48788133],\n",
              "       [0.3128388 ],\n",
              "       [0.94549483],\n",
              "       [0.9905518 ],\n",
              "       [0.992412  ],\n",
              "       [0.96142143],\n",
              "       [0.4887175 ],\n",
              "       [0.09197676],\n",
              "       [0.20595974],\n",
              "       [0.28654906],\n",
              "       [0.9547468 ],\n",
              "       [0.23677695],\n",
              "       [0.932037  ],\n",
              "       [0.64682686],\n",
              "       [0.9507823 ],\n",
              "       [0.09197676],\n",
              "       [0.48788133],\n",
              "       [0.09197676],\n",
              "       [0.09197676],\n",
              "       [0.09197676],\n",
              "       [0.07336649],\n",
              "       [0.09197676],\n",
              "       [0.9547468 ],\n",
              "       [0.09197676],\n",
              "       [0.09731644],\n",
              "       [0.09197676],\n",
              "       [0.96142143],\n",
              "       [0.4400853 ],\n",
              "       [0.40365955],\n",
              "       [0.09197676],\n",
              "       [0.26794666],\n",
              "       [0.09197676],\n",
              "       [0.46909407],\n",
              "       [0.09197676],\n",
              "       [0.48529962],\n",
              "       [0.07336649],\n",
              "       [0.9905518 ],\n",
              "       [0.81911576],\n",
              "       [0.3128388 ],\n",
              "       [0.932037  ],\n",
              "       [0.15465143],\n",
              "       [0.16409877],\n",
              "       [0.16409877],\n",
              "       [0.15465143],\n",
              "       [0.46909407],\n",
              "       [0.14650193],\n",
              "       [0.8266395 ],\n",
              "       [0.6612104 ],\n",
              "       [0.4400853 ],\n",
              "       [0.09197676],\n",
              "       [0.09197676],\n",
              "       [0.28654906],\n",
              "       [0.3128388 ],\n",
              "       [0.09197676],\n",
              "       [0.26794666],\n",
              "       [0.8266395 ],\n",
              "       [0.3128388 ],\n",
              "       [0.3705262 ],\n",
              "       [0.09197676],\n",
              "       [0.09197676],\n",
              "       [0.9337523 ],\n",
              "       [0.29725543],\n",
              "       [0.26794666],\n",
              "       [0.09197676],\n",
              "       [0.09197676],\n",
              "       [0.40365955],\n",
              "       [0.22279716],\n",
              "       [0.09197676],\n",
              "       [0.8266395 ],\n",
              "       [0.9934473 ],\n",
              "       [0.44860995],\n",
              "       [0.13806659],\n",
              "       [0.3705262 ],\n",
              "       [0.41939777],\n",
              "       [0.09197676],\n",
              "       [0.3128388 ],\n",
              "       [0.09197676],\n",
              "       [0.8266395 ],\n",
              "       [0.992412  ],\n",
              "       [0.8266395 ],\n",
              "       [0.48788133],\n",
              "       [0.15465143],\n",
              "       [0.09197676],\n",
              "       [0.17008081],\n",
              "       [0.09197676],\n",
              "       [0.3128388 ],\n",
              "       [0.15465143],\n",
              "       [0.26794666],\n",
              "       [0.9950147 ],\n",
              "       [0.09197676],\n",
              "       [0.9199263 ],\n",
              "       [0.48529962],\n",
              "       [0.16409877],\n",
              "       [0.15465143],\n",
              "       [0.96142143],\n",
              "       [0.48529962],\n",
              "       [0.3128388 ],\n",
              "       [0.6612104 ],\n",
              "       [0.09197676],\n",
              "       [0.26794666],\n",
              "       [0.15465143],\n",
              "       [0.382134  ],\n",
              "       [0.15465143],\n",
              "       [0.3128388 ],\n",
              "       [0.15465143],\n",
              "       [0.09197676],\n",
              "       [0.02654922],\n",
              "       [0.9916959 ],\n",
              "       [0.14650193],\n",
              "       [0.46909407],\n",
              "       [0.15465143],\n",
              "       [0.7105144 ],\n",
              "       [0.15465143],\n",
              "       [0.9547468 ],\n",
              "       [0.9916959 ],\n",
              "       [0.15465137],\n",
              "       [0.15465143],\n",
              "       [0.307303  ],\n",
              "       [0.43557566],\n",
              "       [0.26794666],\n",
              "       [0.9923897 ],\n",
              "       [0.09197676],\n",
              "       [0.07336649],\n",
              "       [0.41939777],\n",
              "       [0.01419416],\n",
              "       [0.93611795],\n",
              "       [0.9547468 ],\n",
              "       [0.09197676],\n",
              "       [0.9905518 ],\n",
              "       [0.07284448],\n",
              "       [0.31632674],\n",
              "       [0.46909407],\n",
              "       [0.9916959 ],\n",
              "       [0.40365955],\n",
              "       [0.16409877],\n",
              "       [0.992412  ],\n",
              "       [0.26794666],\n",
              "       [0.15465143],\n",
              "       [0.9934473 ],\n",
              "       [0.992412  ],\n",
              "       [0.35719687],\n",
              "       [0.15465143],\n",
              "       [0.26794666],\n",
              "       [0.0923962 ],\n",
              "       [0.07336649],\n",
              "       [0.07336649],\n",
              "       [0.46909407],\n",
              "       [0.41939777],\n",
              "       [0.15465143],\n",
              "       [0.9507823 ],\n",
              "       [0.09197676],\n",
              "       [0.15465143],\n",
              "       [0.07336649],\n",
              "       [0.12908342],\n",
              "       [0.26794666],\n",
              "       [0.99469984],\n",
              "       [0.20063901],\n",
              "       [0.15465143],\n",
              "       [0.12908342],\n",
              "       [0.9939499 ],\n",
              "       [0.07336649],\n",
              "       [0.9897622 ],\n",
              "       [0.09197676],\n",
              "       [0.07336649],\n",
              "       [0.9950147 ],\n",
              "       [0.16409877],\n",
              "       [0.9916959 ],\n",
              "       [0.26794666],\n",
              "       [0.48788133],\n",
              "       [0.40365955],\n",
              "       [0.16409877],\n",
              "       [0.4887175 ],\n",
              "       [0.8266395 ],\n",
              "       [0.4400853 ],\n",
              "       [0.8266395 ],\n",
              "       [0.9935808 ],\n",
              "       [0.46909407],\n",
              "       [0.09197676],\n",
              "       [0.992412  ],\n",
              "       [0.09197676],\n",
              "       [0.09197676],\n",
              "       [0.34221566]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7m4JlIROmBP",
        "outputId": "d71347da-fe33-4e47-9826-7ae91c02e095"
      },
      "source": [
        "preds = pred_probs.round().astype(dtype=int)\n",
        "preds"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "SlOVC3HgQPLU",
        "outputId": "52fe7861-1cc2-462a-d79d-f8382d1c905e"
      },
      "source": [
        "Survived = preds\n",
        "Survived = pd.DataFrame(Survived)\n",
        "Survived.head()"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  0\n",
              "2  0\n",
              "3  0\n",
              "4  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "6QV5LHbbQ24-",
        "outputId": "1b7c2706-4882-4369-dc45-dc4d2f8b92bb"
      },
      "source": [
        "test_df1 = pd.read_csv('test.csv')\n",
        "test_df1"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1305</td>\n",
              "      <td>3</td>\n",
              "      <td>Spector, Mr. Woolf</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A.5. 3236</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1306</td>\n",
              "      <td>1</td>\n",
              "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17758</td>\n",
              "      <td>108.9000</td>\n",
              "      <td>C105</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>1307</td>\n",
              "      <td>3</td>\n",
              "      <td>Saether, Mr. Simon Sivertsen</td>\n",
              "      <td>male</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>SOTON/O.Q. 3101262</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>1308</td>\n",
              "      <td>3</td>\n",
              "      <td>Ware, Mr. Frederick</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>359309</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1309</td>\n",
              "      <td>3</td>\n",
              "      <td>Peter, Master. Michael J</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2668</td>\n",
              "      <td>22.3583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Pclass  ... Cabin Embarked\n",
              "0            892       3  ...   NaN        Q\n",
              "1            893       3  ...   NaN        S\n",
              "2            894       2  ...   NaN        Q\n",
              "3            895       3  ...   NaN        S\n",
              "4            896       3  ...   NaN        S\n",
              "..           ...     ...  ...   ...      ...\n",
              "413         1305       3  ...   NaN        S\n",
              "414         1306       1  ...  C105        C\n",
              "415         1307       3  ...   NaN        S\n",
              "416         1308       3  ...   NaN        S\n",
              "417         1309       3  ...   NaN        C\n",
              "\n",
              "[418 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DNq_68SvSTxR",
        "outputId": "f60c3972-840d-41c3-c19a-c710a6a0da69"
      },
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['PassengerID'] = test_df1['PassengerId']\n",
        "submission['Survived'] = Survived[0]\n",
        "submission.head()"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerID</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerID  Survived\n",
              "0          892         0\n",
              "1          893         0\n",
              "2          894         0\n",
              "3          895         0\n",
              "4          896         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kux_xFdnQPXC"
      },
      "source": [
        "submission.to_csv('Neural_Network_submission.csv',index=False)"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKuTKJpFUwU6",
        "outputId": "40bef616-3ddd-44cd-e3f7-18f4ec8b8d90"
      },
      "source": [
        "submission['Survived'].value_counts()"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    302\n",
              "1    116\n",
              "Name: Survived, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    }
  ]
}